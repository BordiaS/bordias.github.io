---
layout: page
<!---
title: About me
-->
---

<h1 align="center">Shikha Bordia</h1>

### Professional Background

I am a Machine Learning Engineer with extensive experience developing scalable NLP, information extraction, and generative AI systems for production. My work focuses on architecting high-performance pipelines, designing evaluation frameworks, and driving reliability across end-to-end ML workflows. I hold multiple U.S. patents and have published in leading conferences, including NAACL, EMNLP, and SDP. My research in debiasing, summarization, and language model analysis has contributed to major responsible AI toolkits from Microsoft, Google, Stanford, and CVS Health.

At Verisk Analytics, I have worked on Discovery Navigator, a leading medical record review platform that processes large volumes of clinical documents. My work spans medical record understanding, legal concept search, and multi-hop fact retrieval, collaborating closely with clinical experts, product teams, and ML Ops to build systems that significantly reduce manual effort and enhance decision quality. I previously earned my MS in Computer Science at NYU’s Courant Institute, working with the [ML^2 Group](https://wp.nyu.edu/ml2/) Lab on bias,linguistic analysis and model interpretability.

Beyond my professional work, I am deeply passionate about yoga, dancing, and biking—practices that bring balance, energy, and creativity to my life. I am also a proud mom to a toddler whose curiosity and joy shape the way I approach learning, resilience, and the meaningful impact of my work.



### Publications/Projects
***Bonafide at LegalLens 2024 Shared Task: Using Lightweight DeBERTa Based Encoder For Legal Violation Detection and Resolution*** \
**Shikha Bordia\*** \
[[Paper](https://arxiv.org/abs/2410.22977)]


***HoVer: A Dataset for Many-Hop Fact Extraction And Claim Verification*** \
Yichen Jiang\*, **Shikha Bordia\***, Zheng Zhong, Charles Dognin, Maneesh Singh, Mohit Bansal \
*Findings of EMNLP 2020* \
[[Paper](https://arxiv.org/abs/2011.03088)][[HoVer Leaderboard](https://hover-nlp.github.io/)] 



***Investigating BERT’s Knowledge of Language: Five Analysis Methods with NPIs*** \
Alex Warstadt\*, Yu Cao\*, Ioana Grosu\*, Wei Peng\*, Hagen Blix\*, Yining Nie\*, Anna Alsop\*, **Shikha Bordia\***, Haokun Liu\*, Alicia Parrish\*, Sheng-Fu Wang\*, Jason Phang\*, Anhad Mohananey\*, Phu Mon Htut\*, Paloma Jeretic\* and Samuel R. Bowman. \
*Proceedings of EMNLP 2019* \
[[Paper](https://arxiv.org/pdf/1909.02597.pdf)][[Slides](https://alexwarstadt.files.wordpress.com/2019/11/npis.pdf)][[Talk](https://vimeo.com/426357616)]



***Identifying and Reducing Gender Bias in Word-Level Language Models*** \
**Shikha Bordia** and Samuel R. Bowman \
*NAACL, Student Research Workshop, 2019* \
[[Paper](https://aclweb.org/anthology/papers/N/N19/N19-3002/)][[Slides](https://bordias.github.io/gender_bias_slides.pdf)][[Poster](https://bordias.github.io/poster.pdf)][[Talk](https://vimeo.com/347400639)]



***On Measuring Social Biases in Sentence Encoders*** \
Chandler May, Alex Wang, **Shikha Bordia**, Samuel R. Bowman, Rachel Rudinger \
*NAACL 2019.* \
[[Paper](https://aclweb.org/anthology/papers/N/N19/N19-1063/)][[Talk](https://vimeo.com/347394290)]


***Do Attention Heads in BERT Track Syntactic Dependencies?*** \
Phu Mon Htut\*, Jason Phang\*, **Shikha Bordia\***, and Samuel R. Bowman. \
*Natural Language, Dialog and Speech (NDS) Symposium, The New York Academy of Sciences. 2019. (Extended Abstract)* \
[[Paper](https://arxiv.org/abs/1911.12246)][[Poster](https://phumonhtut.me/publications/2019NDS/NDSposter.pdf)][[Blog](https://medium.com/@phu_pmh/do-attention-heads-in-bert-track-syntactic-dependencies-81c8a9be311a)]


***Contributed to [jiant](https://github.com/nyu-mll/jiant)*** \
jiant is a work-in-progress software toolkit for natural language processing research, designed to facilitate work on multitask learning and transfer learning for sentence understanding tasks.

### Patents
*Machine learning systems and methods for interactive concept searching using attention scoring (US 11550782, 2023)*

*Machine learning systems and methods for many-hop fact extraction and claim verification (US 12406150, 2025)*

*Systems and Methods for Machine Learning From Medical Records (Accepted)*

<!---
#### Improving pre-training and decoding in Machine Translation
There have been lot of recent advances in Machine Translation that have focused on network architectures, attention mechanisms and sequence-level training. Most of the approaches emphasize on modelling the languages better using attention. Here we explore three methods that rely on augmenting data using a pseudo-parallel corpus, improving the decoding strategy and pre-training the encoders and evaluate their effect on the machine translation task.
--->
<!---
#### Statistical Machine Translation
Implemented a word-based statistical translation model (IBM Model) that extracts phrases using word alignment and performs parameter estimation for partially observed data using expectation maximization.
--->
<!---
#### Text Classifier
Implemented maximum entropy classifier character model and feature extractor code for word classification. Further improved the model by implementing a one layer Perceptron.
--->
<!---
#### Hidden Markov Model for part of speech tagger
Implemented a Hidden Markov model tagger using forward-backward algorithm and Viterbi decoder for unlabeled text data.
--->
<!---
#### Nowcasted Gross Domestic Product
Implemented Stochastic modeling techniques for modeling structured products and the underlying economic variables were now-casted using Autoregressive Integrated Moving Average (ARIMA) model.
--->
<!---
#### Operating System - Process Scheduler and Virtual Memory Manager
Process Scheduler: Implemented scheduling policies  (First In First Out, Last In Last Out, Shortest Job First, RoundRobin and PriorityScheduler) on processes executing on a system using Discrete Event Simulation}
Virtual Memory Manager: Implemented the core features of a virtual memory manager serving multiple processes and under memory constraints.
--->
